# =============================================================================
# Backend Environment Configuration
# =============================================================================
# USAGE: Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# This file is auto-loaded by the backend when running locally:
#   uv run uvicorn requirements_graphrag_api.api:app --reload
#
# Load order (first found wins, existing env vars are NOT overridden):
#   1. backend/.env (this directory)
#   2. root/.env (project root, used by docker-compose)
#
# For Docker: docker-compose uses root/.env via env_file directive
# For Railway: Configure env vars in Railway dashboard
# =============================================================================

# =============================================================================
# Neo4j Connection
# =============================================================================
# Use neo4j+s:// for production (Aura, clusters) - enables TLS and routing
# Use neo4j:// only for local development without TLS
# WARNING: bolt:// does not support cluster routing - avoid for clusters
NEO4J_URI=neo4j+s://your-neo4j-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password-here
NEO4J_DATABASE=neo4j

# Neo4j Driver Configuration (optimized for serverless)
# Smaller pool size reduces cold start time in Vercel/Lambda
NEO4J_MAX_POOL_SIZE=5
# Longer timeout for cold starts in serverless environments
NEO4J_CONNECTION_TIMEOUT=30.0

# =============================================================================
# OpenAI
# =============================================================================
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o
# CRITICAL: Must match the model used to create embeddings in Neo4j!
# The graphrag-api-db database uses text-embedding-3-small
EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# Vector Index Configuration (aligned with actual database)
# =============================================================================
VECTOR_INDEX_NAME=chunk_embeddings
SIMILARITY_K=6

# =============================================================================
# Logging
# =============================================================================
LOG_LEVEL=INFO

# =============================================================================
# LangSmith Observability (Optional)
# =============================================================================
# Enable tracing to LangSmith for debugging and monitoring
# Set to "true" to enable (both env vars supported for compatibility)
LANGSMITH_TRACING=false
# LANGCHAIN_TRACING_V2=false  # Legacy alternative

# LangSmith API key (get from https://smith.langchain.com)
LANGSMITH_API_KEY=
# LANGCHAIN_API_KEY=  # Legacy alternative

# Project name in LangSmith dashboard
LANGSMITH_PROJECT=graphrag-api-dev
# LANGCHAIN_PROJECT=requirements-graphrag  # Legacy alternative

# Organization/workspace handle for LangSmith Hub prompts
# Leave empty or unset to use personal workspace
# Get your handle from https://smith.langchain.com/settings
LANGSMITH_ORG=

# Workspace ID for org-scoped API keys (required for X-Tenant-ID header)
# For org-scoped keys, this is typically the same as your org ID
# Find it at: https://smith.langchain.com/o/<your-org>/settings
LANGSMITH_WORKSPACE_ID=

# Prompt environment (development, staging, production)
# Controls which tagged prompts are pulled from Hub
PROMPT_ENVIRONMENT=development

# =============================================================================
# LangSmith CLI Tools (for debugging with Claude Code)
# =============================================================================
# These variables are also used by langsmith-fetch CLI and langsmith-mcp-server
#
# Install CLI: pip install langsmith-fetch
# Usage: langsmith-fetch traces --limit 5 --format json
#
# MCP Server is configured in .mcp.json and uses these same env vars
# The MCP server provides: prompts, traces, datasets, experiments access
